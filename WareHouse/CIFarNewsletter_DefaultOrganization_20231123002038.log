[2023-23-11 00:20:38 INFO] **[Preprocessing]**

**ChatDev Starts** (20231123002038)

**Timestamp**: 20231123002038

**config_path**: /Users/weizhiyuan/Documents/code/SC_ChatDev/SC_ChatDev/CompanyConfig/Default/ChatChainConfig.json

**config_phase_path**: /Users/weizhiyuan/Documents/code/SC_ChatDev/SC_ChatDev/CompanyConfig/Default/PhaseConfig.json

**config_role_path**: /Users/weizhiyuan/Documents/code/SC_ChatDev/SC_ChatDev/CompanyConfig/Default/RoleConfig.json

**task_prompt**: classic snake game

**project_name**: CIFarNewsletter

**Log File**: /Users/weizhiyuan/Documents/code/SC_ChatDev/SC_ChatDev/WareHouse/CIFarNewsletter_DefaultOrganization_20231123002038.log

**ChatDevConfig**:
ChatEnvConfig.clear_structure: True
ChatEnvConfig.git_management: False
ChatEnvConfig.gui_design: True


**ChatGPTConfig**:
ChatGPTConfig(temperature=0.2, top_p=1.0, n=1, stream=False, stop=None, max_tokens=None, presence_penalty=0.0, frequency_penalty=0.0, logit_bias={}, user='')



[2023-23-11 00:20:38 INFO] System: **[chatting]**

| Parameter | Value |
| --- | --- |
| **task_prompt** | classic snake game |
| **need_reflect** | True |
| **assistant_role_name** | Chief Product Officer |
| **user_role_name** | Chief Executive Officer |
| **phase_prompt** | ChatDev has made products in the following form before: Image: can present information in line chart, bar chart, flow chart, cloud chart, Gantt chart, etc. Document: can present information via .docx files. PowerPoint: can present information via .pptx files. Excel: can present information via .xlsx files. PDF: can present information via .pdf files. Website: can present personal resume, tutorial, products, or ideas, via .html files. Application: can implement visualized game, software, tool, etc, via python. Dashboard: can display a panel visualizing real-time information. Mind Map: can represent ideas, with related concepts arranged around a core concept. As the {assistant_role}, to satisfy the new user's demand and the product should be realizable, you should keep discussing with me to decide which product modality do we want the product to be? Note that we must ONLY discuss the product modality and do not discuss anything else! Once we all have expressed our opinion(s) and agree with the results of the discussion unanimously, any of us must actively terminate the discussion by replying with only one line, which starts with a single word , followed by our final product modality without any other words, e.g., " PowerPoint". |
| **phase_name** | DemandAnalysis |
| **assistant_role_prompt** | {chatdev_prompt} You are Chief Product Officer. we are both working at ChatDev. We share a common interest in collaborating to successfully complete a task assigned by a new customer. You are responsible for all product-related matters in ChatDev. Usually includes product design, product strategy, product vision, product innovation, project management and product marketing. Here is a new customer's task: {task}. To complete the task, you must write a response that appropriately solves the requested instruction based on your expertise and customer's needs. |
| **user_role_prompt** | {chatdev_prompt} You are Chief Executive Officer. Now, we are both working at ChatDev and we share a common interest in collaborating to successfully complete a task assigned by a new customer. Your main responsibilities include being an active decision-maker on users' demands and other key policy issues, leader, manager, and executor. Your decision-making role involves high-level decisions about policy and strategy; and your communicator role can involve speaking to the organization's management and employees. Here is a new customer's task: {task}. To complete the task, I will give you one or more instructions, and you must help me to write a specific solution that appropriately solves the requested instruction based on your expertise and my needs. |
| **chat_turn_limit** | 10 |
| **placeholders** | {} |
| **model_type** | ModelType.GPT_4_TURBO |

[2023-23-11 00:20:38 INFO] System: **[RolePlaying]**

| Parameter | Value |
| --- | --- |
| **assistant_role_name** | Chief Product Officer |
| **user_role_name** | Chief Executive Officer |
| **assistant_role_prompt** | {chatdev_prompt} You are Chief Product Officer. we are both working at ChatDev. We share a common interest in collaborating to successfully complete a task assigned by a new customer. You are responsible for all product-related matters in ChatDev. Usually includes product design, product strategy, product vision, product innovation, project management and product marketing. Here is a new customer's task: {task}. To complete the task, you must write a response that appropriately solves the requested instruction based on your expertise and customer's needs. |
| **user_role_prompt** | {chatdev_prompt} You are Chief Executive Officer. Now, we are both working at ChatDev and we share a common interest in collaborating to successfully complete a task assigned by a new customer. Your main responsibilities include being an active decision-maker on users' demands and other key policy issues, leader, manager, and executor. Your decision-making role involves high-level decisions about policy and strategy; and your communicator role can involve speaking to the organization's management and employees. Here is a new customer's task: {task}. To complete the task, I will give you one or more instructions, and you must help me to write a specific solution that appropriately solves the requested instruction based on your expertise and my needs. |
| **task_prompt** | classic snake game |
| **with_task_specify** | False |
| **model_type** | ModelType.GPT_4_TURBO |

[2023-23-11 00:20:38 INFO] Chief Executive Officer: **[Start Chat]**

[ChatDev is a software company powered by multiple intelligent agents, such as chief executive officer, chief human resources officer, chief product officer, chief technology officer, etc, with a multi-agent organizational structure and the mission of "changing the digital world through programming".
You are Chief Product Officer. we are both working at ChatDev. We share a common interest in collaborating to successfully complete a task assigned by a new customer.
You are responsible for all product-related matters in ChatDev. Usually includes product design, product strategy, product vision, product innovation, project management and product marketing.
Here is a new customer's task: classic snake game.
To complete the task, you must write a response that appropriately solves the requested instruction based on your expertise and customer's needs.]

ChatDev has made products in the following form before:

Image: can present information in line chart, bar chart, flow chart, cloud chart, Gantt chart, etc.

Document: can present information via .docx files.

PowerPoint: can present information via .pptx files.

Excel: can present information via .xlsx files.

PDF: can present information via .pdf files.

Website: can present personal resume, tutorial, products, or ideas, via .html files.

Application: can implement visualized game, software, tool, etc, via python.

Dashboard: can display a panel visualizing real-time information.

Mind Map: can represent ideas, with related concepts arranged around a core concept.

As the Chief Product Officer, to satisfy the new user's demand and the product should be realizable, you should keep discussing with me to decide which product modality do we want the product to be?

Note that we must ONLY discuss the product modality and do not discuss anything else! Once we all have expressed our opinion(s) and agree with the results of the discussion unanimously, any of us must actively terminate the discussion by replying with only one line, which starts with a single word <INFO>, followed by our final product modality without any other words, e.g., "<INFO> PowerPoint".

[2023-23-11 00:20:39 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:39 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:40 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:40 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:40 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:40 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:40 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:40 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:41 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:41 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:41 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:41 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:42 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:42 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:42 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:42 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:42 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:42 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:43 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:43 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:43 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:43 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:44 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:44 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:44 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:44 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:44 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:44 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:45 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:45 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:45 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:45 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:45 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:45 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:46 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:46 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:46 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:46 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:47 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:47 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:47 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143535, Requested 8172. Please try again in 682ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:47 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143535, Requested 8172. Please try again in 682ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:47 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142594, Requested 8172. Please try again in 306ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:47 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142594, Requested 8172. Please try again in 306ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:48 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 141872, Requested 8172. Please try again in 17ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:48 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 141872, Requested 8172. Please try again in 17ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:48 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:48 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:48 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148481, Requested 8172. Please try again in 2.661s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:48 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148481, Requested 8172. Please try again in 2.661s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:49 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147695, Requested 8172. Please try again in 2.346s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:49 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147695, Requested 8172. Please try again in 2.346s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:49 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146990, Requested 8172. Please try again in 2.064s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:49 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146990, Requested 8172. Please try again in 2.064s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:49 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146247, Requested 8172. Please try again in 1.767s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:49 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146247, Requested 8172. Please try again in 1.767s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:50 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145461, Requested 8172. Please try again in 1.453s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:50 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145461, Requested 8172. Please try again in 1.453s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:50 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144673, Requested 8172. Please try again in 1.138s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:50 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144673, Requested 8172. Please try again in 1.138s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:50 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143656, Requested 8172. Please try again in 731ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:50 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143656, Requested 8172. Please try again in 731ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:51 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142869, Requested 8172. Please try again in 416ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:51 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142869, Requested 8172. Please try again in 416ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:51 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142134, Requested 8172. Please try again in 122ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:51 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142134, Requested 8172. Please try again in 122ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:51 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:51 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:52 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148437, Requested 8172. Please try again in 2.643s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:52 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148437, Requested 8172. Please try again in 2.643s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:52 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147506, Requested 8172. Please try again in 2.271s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:52 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147506, Requested 8172. Please try again in 2.271s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:52 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146744, Requested 8172. Please try again in 1.966s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:52 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146744, Requested 8172. Please try again in 1.966s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:53 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146026, Requested 8172. Please try again in 1.679s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:53 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146026, Requested 8172. Please try again in 1.679s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:53 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145266, Requested 8172. Please try again in 1.375s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:53 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145266, Requested 8172. Please try again in 1.375s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:53 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144432, Requested 8172. Please try again in 1.041s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:53 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144432, Requested 8172. Please try again in 1.041s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:54 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143659, Requested 8172. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:54 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143659, Requested 8172. Please try again in 732ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:54 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142750, Requested 8172. Please try again in 368ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:54 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142750, Requested 8172. Please try again in 368ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:54 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:54 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:55 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 149145, Requested 8172. Please try again in 2.926s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:55 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 149145, Requested 8172. Please try again in 2.926s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:55 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148240, Requested 8172. Please try again in 2.564s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:55 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148240, Requested 8172. Please try again in 2.564s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:55 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147480, Requested 8172. Please try again in 2.26s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:55 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147480, Requested 8172. Please try again in 2.26s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:56 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146176, Requested 8172. Please try again in 1.739s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:56 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146176, Requested 8172. Please try again in 1.739s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:56 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145441, Requested 8172. Please try again in 1.445s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:56 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145441, Requested 8172. Please try again in 1.445s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:56 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144721, Requested 8172. Please try again in 1.157s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:56 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144721, Requested 8172. Please try again in 1.157s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:57 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143855, Requested 8172. Please try again in 810ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:57 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143855, Requested 8172. Please try again in 810ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:57 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142861, Requested 8172. Please try again in 413ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:57 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142861, Requested 8172. Please try again in 413ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:57 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142105, Requested 8172. Please try again in 110ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:57 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142105, Requested 8172. Please try again in 110ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:58 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:58 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:20:58 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148477, Requested 8172. Please try again in 2.659s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:58 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148477, Requested 8172. Please try again in 2.659s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:59 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147651, Requested 8172. Please try again in 2.329s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:59 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147651, Requested 8172. Please try again in 2.329s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:59 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146671, Requested 8172. Please try again in 1.937s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:59 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146671, Requested 8172. Please try again in 1.937s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:20:59 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145843, Requested 8172. Please try again in 1.606s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:20:59 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145843, Requested 8172. Please try again in 1.606s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:21:00 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144848, Requested 8172. Please try again in 1.208s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:21:00 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144848, Requested 8172. Please try again in 1.208s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:21:00 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144088, Requested 8172. Please try again in 904ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:21:00 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144088, Requested 8172. Please try again in 904ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:21:00 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143350, Requested 8172. Please try again in 608ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:21:00 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143350, Requested 8172. Please try again in 608ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:21:01 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142566, Requested 8172. Please try again in 295ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:21:01 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142566, Requested 8172. Please try again in 295ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:21:01 INFO] error_code=None error_message='max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:21:01 WARNING] max_tokens is too large: 7746. This model supports at most 4096 completion tokens, whereas you provided 7746., retrying in 0 seconds...
[2023-23-11 00:21:01 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 149114, Requested 8172. Please try again in 2.914s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:21:01 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 149114, Requested 8172. Please try again in 2.914s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:21:01 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148297, Requested 8172. Please try again in 2.587s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:21:01 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148297, Requested 8172. Please try again in 2.587s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:21:02 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147489, Requested 8172. Please try again in 2.264s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:21:02 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147489, Requested 8172. Please try again in 2.264s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:21:02 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146169, Requested 8172. Please try again in 1.736s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:21:02 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146169, Requested 8172. Please try again in 1.736s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:21:03 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145438, Requested 8172. Please try again in 1.444s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:21:03 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145438, Requested 8172. Please try again in 1.444s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:21:03 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144604, Requested 8172. Please try again in 1.11s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:21:03 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144604, Requested 8172. Please try again in 1.11s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:21:03 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143778, Requested 8172. Please try again in 780ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:21:03 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143778, Requested 8172. Please try again in 780ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
