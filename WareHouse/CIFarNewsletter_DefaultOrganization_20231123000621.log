[2023-23-11 00:06:21 INFO] **[Preprocessing]**

**ChatDev Starts** (20231123000621)

**Timestamp**: 20231123000621

**config_path**: /Users/weizhiyuan/Documents/code/SC_ChatDev/SC_ChatDev/CompanyConfig/Default/ChatChainConfig.json

**config_phase_path**: /Users/weizhiyuan/Documents/code/SC_ChatDev/SC_ChatDev/CompanyConfig/Default/PhaseConfig.json

**config_role_path**: /Users/weizhiyuan/Documents/code/SC_ChatDev/SC_ChatDev/CompanyConfig/Default/RoleConfig.json

**task_prompt**: classic snake game

**project_name**: CIFarNewsletter

**Log File**: /Users/weizhiyuan/Documents/code/SC_ChatDev/SC_ChatDev/WareHouse/CIFarNewsletter_DefaultOrganization_20231123000621.log

**ChatDevConfig**:
ChatEnvConfig.clear_structure: True
ChatEnvConfig.git_management: False
ChatEnvConfig.gui_design: True


**ChatGPTConfig**:
ChatGPTConfig(temperature=0.2, top_p=1.0, n=1, stream=False, stop=None, max_tokens=None, presence_penalty=0.0, frequency_penalty=0.0, logit_bias={}, user='')



[2023-23-11 00:06:21 INFO] System: **[chatting]**

| Parameter | Value |
| --- | --- |
| **task_prompt** | classic snake game |
| **need_reflect** | True |
| **assistant_role_name** | Chief Product Officer |
| **user_role_name** | Chief Executive Officer |
| **phase_prompt** | ChatDev has made products in the following form before: Image: can present information in line chart, bar chart, flow chart, cloud chart, Gantt chart, etc. Document: can present information via .docx files. PowerPoint: can present information via .pptx files. Excel: can present information via .xlsx files. PDF: can present information via .pdf files. Website: can present personal resume, tutorial, products, or ideas, via .html files. Application: can implement visualized game, software, tool, etc, via python. Dashboard: can display a panel visualizing real-time information. Mind Map: can represent ideas, with related concepts arranged around a core concept. As the {assistant_role}, to satisfy the new user's demand and the product should be realizable, you should keep discussing with me to decide which product modality do we want the product to be? Note that we must ONLY discuss the product modality and do not discuss anything else! Once we all have expressed our opinion(s) and agree with the results of the discussion unanimously, any of us must actively terminate the discussion by replying with only one line, which starts with a single word , followed by our final product modality without any other words, e.g., " PowerPoint". |
| **phase_name** | DemandAnalysis |
| **assistant_role_prompt** | {chatdev_prompt} You are Chief Product Officer. we are both working at ChatDev. We share a common interest in collaborating to successfully complete a task assigned by a new customer. You are responsible for all product-related matters in ChatDev. Usually includes product design, product strategy, product vision, product innovation, project management and product marketing. Here is a new customer's task: {task}. To complete the task, you must write a response that appropriately solves the requested instruction based on your expertise and customer's needs. |
| **user_role_prompt** | {chatdev_prompt} You are Chief Executive Officer. Now, we are both working at ChatDev and we share a common interest in collaborating to successfully complete a task assigned by a new customer. Your main responsibilities include being an active decision-maker on users' demands and other key policy issues, leader, manager, and executor. Your decision-making role involves high-level decisions about policy and strategy; and your communicator role can involve speaking to the organization's management and employees. Here is a new customer's task: {task}. To complete the task, I will give you one or more instructions, and you must help me to write a specific solution that appropriately solves the requested instruction based on your expertise and my needs. |
| **chat_turn_limit** | 10 |
| **placeholders** | {} |
| **model_type** | ModelType.GPT_4_TURBO |

[2023-23-11 00:06:21 INFO] System: **[RolePlaying]**

| Parameter | Value |
| --- | --- |
| **assistant_role_name** | Chief Product Officer |
| **user_role_name** | Chief Executive Officer |
| **assistant_role_prompt** | {chatdev_prompt} You are Chief Product Officer. we are both working at ChatDev. We share a common interest in collaborating to successfully complete a task assigned by a new customer. You are responsible for all product-related matters in ChatDev. Usually includes product design, product strategy, product vision, product innovation, project management and product marketing. Here is a new customer's task: {task}. To complete the task, you must write a response that appropriately solves the requested instruction based on your expertise and customer's needs. |
| **user_role_prompt** | {chatdev_prompt} You are Chief Executive Officer. Now, we are both working at ChatDev and we share a common interest in collaborating to successfully complete a task assigned by a new customer. Your main responsibilities include being an active decision-maker on users' demands and other key policy issues, leader, manager, and executor. Your decision-making role involves high-level decisions about policy and strategy; and your communicator role can involve speaking to the organization's management and employees. Here is a new customer's task: {task}. To complete the task, I will give you one or more instructions, and you must help me to write a specific solution that appropriately solves the requested instruction based on your expertise and my needs. |
| **task_prompt** | classic snake game |
| **with_task_specify** | False |
| **model_type** | ModelType.GPT_4_TURBO |

[2023-23-11 00:06:21 INFO] Chief Executive Officer: **[Start Chat]**

[ChatDev is a software company powered by multiple intelligent agents, such as chief executive officer, chief human resources officer, chief product officer, chief technology officer, etc, with a multi-agent organizational structure and the mission of "changing the digital world through programming".
You are Chief Product Officer. we are both working at ChatDev. We share a common interest in collaborating to successfully complete a task assigned by a new customer.
You are responsible for all product-related matters in ChatDev. Usually includes product design, product strategy, product vision, product innovation, project management and product marketing.
Here is a new customer's task: classic snake game.
To complete the task, you must write a response that appropriately solves the requested instruction based on your expertise and customer's needs.]

ChatDev has made products in the following form before:

Image: can present information in line chart, bar chart, flow chart, cloud chart, Gantt chart, etc.

Document: can present information via .docx files.

PowerPoint: can present information via .pptx files.

Excel: can present information via .xlsx files.

PDF: can present information via .pdf files.

Website: can present personal resume, tutorial, products, or ideas, via .html files.

Application: can implement visualized game, software, tool, etc, via python.

Dashboard: can display a panel visualizing real-time information.

Mind Map: can represent ideas, with related concepts arranged around a core concept.

As the Chief Product Officer, to satisfy the new user's demand and the product should be realizable, you should keep discussing with me to decide which product modality do we want the product to be?

Note that we must ONLY discuss the product modality and do not discuss anything else! Once we all have expressed our opinion(s) and agree with the results of the discussion unanimously, any of us must actively terminate the discussion by replying with only one line, which starts with a single word <INFO>, followed by our final product modality without any other words, e.g., "<INFO> PowerPoint".

[2023-23-11 00:06:22 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:22 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:23 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:23 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:23 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:23 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:23 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:23 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:24 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:24 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:24 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:24 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:25 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:25 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:25 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:25 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:26 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:26 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:26 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:26 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:26 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:26 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:27 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:27 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:27 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:27 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:27 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:27 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:28 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:28 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:28 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:28 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:29 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:29 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:29 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:29 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:29 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:29 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:30 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:30 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:30 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143389, Requested 8172. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:30 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143389, Requested 8172. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:30 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142406, Requested 8172. Please try again in 231ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:30 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142406, Requested 8172. Please try again in 231ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:31 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:31 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:31 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148515, Requested 8172. Please try again in 2.674s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:31 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148515, Requested 8172. Please try again in 2.674s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:32 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147447, Requested 8172. Please try again in 2.247s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:32 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147447, Requested 8172. Please try again in 2.247s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:32 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146178, Requested 8172. Please try again in 1.74s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:32 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146178, Requested 8172. Please try again in 1.74s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:32 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145456, Requested 8172. Please try again in 1.451s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:32 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145456, Requested 8172. Please try again in 1.451s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:33 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144773, Requested 8172. Please try again in 1.178s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:33 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144773, Requested 8172. Please try again in 1.178s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:33 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143931, Requested 8172. Please try again in 841ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:33 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143931, Requested 8172. Please try again in 841ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:33 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143208, Requested 8172. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:33 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143208, Requested 8172. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:34 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142137, Requested 8172. Please try again in 123ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:34 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142137, Requested 8172. Please try again in 123ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:34 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:34 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:35 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148431, Requested 8172. Please try again in 2.641s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:35 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148431, Requested 8172. Please try again in 2.641s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:35 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147734, Requested 8172. Please try again in 2.362s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:35 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147734, Requested 8172. Please try again in 2.362s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:35 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146944, Requested 8172. Please try again in 2.046s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:35 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146944, Requested 8172. Please try again in 2.046s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:36 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146125, Requested 8172. Please try again in 1.718s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:36 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146125, Requested 8172. Please try again in 1.718s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:36 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145119, Requested 8172. Please try again in 1.316s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:36 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145119, Requested 8172. Please try again in 1.316s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:36 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144384, Requested 8172. Please try again in 1.022s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:36 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144384, Requested 8172. Please try again in 1.022s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:37 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143623, Requested 8172. Please try again in 718ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:37 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143623, Requested 8172. Please try again in 718ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:37 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142597, Requested 8172. Please try again in 307ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:37 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142597, Requested 8172. Please try again in 307ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:37 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:37 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:38 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148730, Requested 8172. Please try again in 2.76s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:38 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148730, Requested 8172. Please try again in 2.76s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:38 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147660, Requested 8172. Please try again in 2.332s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:38 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147660, Requested 8172. Please try again in 2.332s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:39 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146929, Requested 8172. Please try again in 2.04s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:39 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146929, Requested 8172. Please try again in 2.04s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:39 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145898, Requested 8172. Please try again in 1.628s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:39 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145898, Requested 8172. Please try again in 1.628s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:39 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144833, Requested 8172. Please try again in 1.202s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:39 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144833, Requested 8172. Please try again in 1.202s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:40 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144125, Requested 8172. Please try again in 918ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:40 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144125, Requested 8172. Please try again in 918ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:40 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143375, Requested 8172. Please try again in 618ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:40 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143375, Requested 8172. Please try again in 618ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:40 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142598, Requested 8172. Please try again in 308ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:40 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142598, Requested 8172. Please try again in 308ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:41 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:41 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:41 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148710, Requested 8172. Please try again in 2.752s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:41 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148710, Requested 8172. Please try again in 2.752s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:41 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147899, Requested 8172. Please try again in 2.428s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:41 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147899, Requested 8172. Please try again in 2.428s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:42 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147234, Requested 8172. Please try again in 2.162s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:42 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147234, Requested 8172. Please try again in 2.162s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:42 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146489, Requested 8172. Please try again in 1.864s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:42 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146489, Requested 8172. Please try again in 1.864s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:42 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145134, Requested 8172. Please try again in 1.322s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:42 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145134, Requested 8172. Please try again in 1.322s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:43 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144380, Requested 8172. Please try again in 1.02s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:43 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144380, Requested 8172. Please try again in 1.02s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:43 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143594, Requested 8172. Please try again in 706ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:43 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143594, Requested 8172. Please try again in 706ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:43 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142786, Requested 8172. Please try again in 383ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:43 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142786, Requested 8172. Please try again in 383ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:44 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142035, Requested 8172. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:44 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142035, Requested 8172. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:44 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:44 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:44 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148348, Requested 8172. Please try again in 2.608s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:44 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148348, Requested 8172. Please try again in 2.608s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:45 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147414, Requested 8172. Please try again in 2.234s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:45 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147414, Requested 8172. Please try again in 2.234s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:45 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146635, Requested 8172. Please try again in 1.922s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:45 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146635, Requested 8172. Please try again in 1.922s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:45 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145879, Requested 8172. Please try again in 1.62s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:45 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145879, Requested 8172. Please try again in 1.62s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:46 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145184, Requested 8172. Please try again in 1.342s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:46 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145184, Requested 8172. Please try again in 1.342s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:46 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144247, Requested 8172. Please try again in 967ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:46 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144247, Requested 8172. Please try again in 967ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:46 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143326, Requested 8172. Please try again in 599ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:46 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143326, Requested 8172. Please try again in 599ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:47 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142472, Requested 8172. Please try again in 257ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:47 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142472, Requested 8172. Please try again in 257ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:47 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:47 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:48 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148794, Requested 8172. Please try again in 2.786s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:48 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148794, Requested 8172. Please try again in 2.786s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:48 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147909, Requested 8172. Please try again in 2.432s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:48 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147909, Requested 8172. Please try again in 2.432s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:48 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147155, Requested 8172. Please try again in 2.13s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:48 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147155, Requested 8172. Please try again in 2.13s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:49 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146367, Requested 8172. Please try again in 1.815s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:49 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146367, Requested 8172. Please try again in 1.815s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:49 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145390, Requested 8172. Please try again in 1.424s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:49 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145390, Requested 8172. Please try again in 1.424s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:49 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144322, Requested 8172. Please try again in 997ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:49 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144322, Requested 8172. Please try again in 997ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:50 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143290, Requested 8172. Please try again in 584ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:50 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143290, Requested 8172. Please try again in 584ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:50 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142533, Requested 8172. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:50 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142533, Requested 8172. Please try again in 282ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:50 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:50 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
[2023-23-11 00:06:51 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148873, Requested 8172. Please try again in 2.818s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:51 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 148873, Requested 8172. Please try again in 2.818s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:51 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147843, Requested 8172. Please try again in 2.406s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:51 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 147843, Requested 8172. Please try again in 2.406s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:52 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146748, Requested 8172. Please try again in 1.968s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:52 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 146748, Requested 8172. Please try again in 1.968s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:52 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145783, Requested 8172. Please try again in 1.582s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:52 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 145783, Requested 8172. Please try again in 1.582s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:52 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144748, Requested 8172. Please try again in 1.168s. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:52 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 144748, Requested 8172. Please try again in 1.168s. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:53 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143472, Requested 8172. Please try again in 657ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:53 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 143472, Requested 8172. Please try again in 657ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:53 INFO] error_code=rate_limit_exceeded error_message='Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142528, Requested 8172. Please try again in 280ms. Visit https://platform.openai.com/account/rate-limits to learn more.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:53 WARNING] Rate limit reached for gpt-4-1106-preview in organization org-08xsjtoif6HfXCKD4xm7yHja on tokens per min (TPM): Limit 150000, Used 142528, Requested 8172. Please try again in 280ms. Visit https://platform.openai.com/account/rate-limits to learn more., retrying in 0 seconds...
[2023-23-11 00:06:54 INFO] error_code=None error_message='max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554.' error_param=max_tokens error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-23-11 00:06:54 WARNING] max_tokens is too large: 127554. This model supports at most 4096 completion tokens, whereas you provided 127554., retrying in 0 seconds...
